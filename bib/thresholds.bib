% Encoding: UTF-8

@InProceedings{Serafin2013,
  author        = {Serafin, Stefania and Nilsson, Niels C and Sikstrom, Erik and De Goetzen, Amalia and Nordahl, Rolf},
  title         = {Estimation of detection thresholds for acoustic based redirected walking techniques},
  booktitle     = {Virtual Reality (VR), 2013 IEEE},
  year          = {2013},
  pages         = {161--162},
  organization  = {IEEE},
  __markedentry = {[Admin:6]},
}

@InProceedings{Steinicke2008,
  author        = {Steinicke, Frank and Bruder, Gerd and Jerald, Jason and Frenz, Harald and Lappe, Markus},
  title         = {Analyses of human sensitivity to redirected walking},
  booktitle     = {Proceedings of the 2008 ACM symposium on Virtual reality software and technology},
  year          = {2008},
  pages         = {149--156},
  organization  = {ACM},
  __markedentry = {[Admin:6]},
}

@InProceedings{Bruder2009,
  author        = {Bruder, Gerd and Steinicke, Frank and Hinrichs, Klaus H and Frenz, Harald and Lappe, Markus},
  title         = {Impact of gender on discrimination between real and virtual stimuli},
  booktitle     = {Workshop on Perceptual Illusions in Virtual Environments},
  year          = {2009},
  pages         = {10--15},
  __markedentry = {[Admin:6]},
}

@InProceedings{Grechkin2016,
  author        = {Grechkin, Timofey and Thomas, Jerald and Azmandian, Mahdi and Bolas, Mark and Suma, Evan},
  title         = {Revisiting detection thresholds for redirected walking: Combining translation and curvature gains},
  booktitle     = {Proceedings of the ACM Symposium on Applied Perception},
  year          = {2016},
  pages         = {113--120},
  organization  = {ACM},
  __markedentry = {[Admin:6]},
}

@InProceedings{Chen2014,
  author        = {Chen, Karen B and Ponto, Kevin and Sesto, Mary E and Radwin, Robert G},
  title         = {Influence of altered visual feedback on neck movement for a virtual reality rehabilitative system},
  booktitle     = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  year          = {2014},
  volume        = {58},
  number        = {1},
  pages         = {693--697},
  organization  = {SAGE Publications Sage CA: Los Angeles, CA},
  __markedentry = {[Admin:6]},
}

@InProceedings{Paludan2016,
  author        = {Paludan, Anders and Elbaek, Jacob and Mortensen, Mathias and Zobbe, Morten and Nilsson, Niels Christian and Nordahl, Rolf and Reng, Lars and Serafin, Stefania},
  title         = {Disguising rotational gain for redirected walking in virtual reality: Effect of visual density},
  booktitle     = {Virtual Reality (VR), 2016 IEEE},
  year          = {2016},
  pages         = {259--260},
  organization  = {IEEE},
  __markedentry = {[Admin:6]},
}

@Article{Steinicke2010,
  author        = {Steinicke, Frank and Bruder, Gerd and Jerald, Jason and Frenz, Harald and Lappe, Markus},
  title         = {Estimation of detection thresholds for redirected walking techniques},
  journal       = {IEEE transactions on visualization and computer graphics},
  year          = {2010},
  volume        = {16},
  number        = {1},
  pages         = {17--27},
  __markedentry = {[Admin:6]},
  publisher     = {IEEE},
}

@Article{Neira2012,
  author        = {Neira, C Cruz and Kiyokawa, K and Roberts, D},
  title         = {Redirected Steering for Virtual Self-Motion Control with a Motorized Electric Wheelchair},
  year          = {2012},
  __markedentry = {[Admin:6]},
}

@Article{Meyer2016,
  author        = {Meyer, Florian and Nogalski, Malte and Fohl, Wolfgang},
  title         = {DETECTION THRESHOLDS IN AUDIO-VISUAL REDIRECTED WALKING},
  year          = {2016},
  __markedentry = {[Admin:6]},
}

@Article{neth2012velocity,
  author    = {Neth, Christian T and Souman, Jan L and Engel, David and Kloos, Uwe and Bulthoff, Heinrich H and Mohler, Betty J},
  title     = {Velocity-dependent dynamic curvature gain for redirected walking},
  journal   = {IEEE transactions on visualization and computer graphics},
  year      = {2012},
  volume    = {18},
  number    = {7},
  pages     = {1041--1052},
  publisher = {IEEE},
  review    = {Provides information regarding curvature gain thresholds at different speeds. Also includes step analysis.},
}

@Article{bruder2012redirecting,
  author    = {Bruder, Gerd and Interrante, Victoria and Phillips, Lane and Steinicke, Frank},
  title     = {Redirecting walking and driving for natural navigation in immersive virtual environments},
  journal   = {IEEE transactions on visualization and computer graphics},
  year      = {2012},
  volume    = {18},
  number    = {4},
  pages     = {538--545},
  publisher = {IEEE},
  review    = {Compares the 3 main gains with wheelchair and walking.},
}

@InProceedings{steinicke2008moving,
  author       = {Steinicke, Frank and Bruder, Gerd and Ropinski, Timo and Hinrichs, Klaus},
  title        = {Moving towards generally applicable redirected walking},
  booktitle    = {Proceedings of the Virtual Reality International Conference (VRIC)},
  year         = {2008},
  pages        = {15--24},
  organization = {IEEE Press},
  review       = {Contains detection thresholds for 3 main gains but did not use 2AFC.},
}

@Article{Frenz2007,
  author        = {Frenz, Harald and Lappe, Markus and Kolesnik, Marina and B{\"u}hrmann, Thomas},
  title         = {Estimation of travel distance from visual motion in virtual environments},
  journal       = {ACM Transactions on Applied Perception (TAP)},
  year          = {2007},
  volume        = {4},
  number        = {1},
  pages         = {3},
  __markedentry = {[Admin:6]},
  abstract      = {Distance estimation of visually simulated self-motion is difficult, because one has to know or make assumptions about scene
layout to judge ego speed. Discrimination of the travel distances of two sequentially simulated self-motions in the same scene can
be performed quite accurately (Bremmer and Lappe 1999; Frenz et al., 2003). However, the indication of the perceived distance
of a single movement in terms of a spatial interval results in a depth scaling error: Intervals are correlated with the true travel
distance, but underestimate travel distance by about 25% (Frenz and Lappe, 2005). Here we investigated whether the inclusion of
further depth cues (disparity/motion parallax/figural cues) in the virtual environment allows more veridical interval adjustment.
Experiments were conducted on a large single projection screen and in a fully immersive computer-animated virtual environment
(CAVE). Forward movements in simple virtual environments were simulated with distances between 1.5 and 13 m with varying
speeds. Subjects indicated the perceived distance of each movement in terms of a depth interval on the virtual ground plane.
We found good correlation between simulated and indicated distances, indicative of an internal representation of the perceived
distance. The slopes of the fitted regression lines revealed an underestimation of distance by about 25% under all conditions.
We conclude that estimation of travel distance from optic flow is subject to scaling when compared to static intervals in the
environment, irrespective of additional depth cues.},
  groups        = {Vr Locomotion},
  publisher     = {ACM},
  review        = {Early information regarding translation gain. May contain thresholds value.},
}

@Article{Traschuetz2012,
  author        = {Trasch{\"u}tz, Andreas and Zinke, Wolf and Wegener, Detlef},
  title         = {Speed change detection in foveal and peripheral vision},
  journal       = {Vision research},
  year          = {2012},
  volume        = {72},
  pages         = {1--13},
  __markedentry = {[Admin:6]},
  abstract      = {Perception of constant motion has been extensively studied both psychophysically and physiologically, but the human ability to detect dynamic changes in motion, such as rapid speed changes, is only poorly characterized and understood. Yet, perception and representation of such dynamic changes is of strong behavioral relevance, as illustrated by their potential for attentional capture. In the present study, we measured and compared detection thresholds for instantaneous accelerations and decelerations of drifting Gabor patches at different retinal eccentricities. As a main result, we find that detection performance depends strongly on eccentricity. Under foveal viewing conditions, average thresholds were lower for accelerations than for decelerations. However, between 5° and 15° eccentricity, this relation is inverted, and deceleration detection becomes better than acceleration detection. Results of an additional experiment suggest that this can be explained by a fast eccentricity-dependent adaptation effect. Our findings are discussed with special emphasis on their relation to data from neurophysiological experiments.},
  publisher     = {Elsevier},
  review        = {Perfroms evaluation of translation gain. Contains information regarding fov and its influence.},
}

@InProceedings{Engel2008,
  author        = {Engel, David and Curio, Crist{\'o}bal and Tcheang, Lili and Mohler, Betty and B{\"u}lthoff, Heinrich H},
  title         = {A psychophysically calibrated controller for navigating through large environments in a limited free-walking space},
  booktitle     = {Proceedings of the 2008 ACM symposium on Virtual reality software and technology},
  year          = {2008},
  pages         = {157--164},
  organization  = {ACM},
  __markedentry = {[Admin:6]},
  abstract      = {Experience indicates that the sense of presence in a virtual environment is enhanced when the participants are able to actively move through it. When exploring a virtual world by walking, the size of the model is usually limited by the size of the available tracking space. A promising way to overcome these limitations are motion compression techniques, which decouple the position in the real and virtual world by introducing imperceptible visual-proprioceptive conflicts. Such techniques usually precalculate the redirection factors, greatly reducing their robustness. We propose a novel way to determine the instantaneous rotational gains using a controller based on an optimization problem. We present a psychophysical study that measures the sensitivity of visual-proprioceptive conflicts during walking and use this to calibrate a real-time controller. We show the validity of our approach by allowing users to walk through virtual environments vastly larger than the tracking space.},
}

@Comment{jabref-meta: databaseType:bibtex;}
